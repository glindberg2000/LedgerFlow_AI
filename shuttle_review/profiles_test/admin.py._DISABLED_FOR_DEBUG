from django.contrib import admin

admin.site.site_header = "LedgerFlow Admin"
admin.site.site_title = "LedgerFlow Admin"
admin.site.index_title = "LedgerFlow Admin"

from .models import (
    BusinessProfile,
    Transaction,
    LLMConfig,
    Agent,
    Tool,
    NormalizedVendorData,
    IRSWorksheet,
    IRSExpenseCategory,
    BusinessExpenseCategory,
    TransactionClassification,
    ProcessingTask,
    StatementFile,
    CLASSIFICATION_METHOD_UNCLASSIFIED,
    PAYEE_EXTRACTION_METHOD_UNPROCESSED,
    ParsingRun,
)
from django.utils.translation import gettext_lazy as _
from django.http import HttpResponseRedirect
from django.urls import path, reverse
from django.shortcuts import render, get_object_or_404, redirect
from django.contrib import messages
import json
from jsonschema import validate, ValidationError
import requests
import os
from dotenv import load_dotenv
import logging
import traceback
from openai import OpenAI
import sys
from datetime import datetime
from django.utils import timezone
from pathlib import Path
import subprocess
from django.conf import settings
from django.db import transaction as db_transaction
from django import forms
from django.utils.html import format_html
import re
from .utils import (
    extract_pdf_metadata,
    get_update_fields_from_response,
    sync_transaction_id_sequence,
)
from django.template.response import TemplateResponse
from django.contrib.admin import AdminSite
from django.utils.safestring import mark_safe
import importlib
import pkgutil
from dataextractai.utils.normalize_api import normalize_parsed_data_df
from django.core.exceptions import ValidationError
import pandas as pd
import tempfile
from django.core.files import File
from profiles.parsers_utilities.models import ImportedParser

# Add the root directory to the Python path
sys.path.append(
    os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
)

# Load environment variables
load_dotenv()

# Configure logging
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
handler = logging.StreamHandler()
handler.setFormatter(
    logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
)
logger.addHandler(handler)


class BusinessProfileAdminForm(forms.ModelForm):
    business_description = forms.CharField(
        required=True,
        widget=forms.Textarea(attrs={"rows": 3, "cols": 60}),
        help_text="Describe your business in your own words. The AI will generate the rest of your business profile.",
    )
    contact_info = forms.CharField(
        required=False,
        widget=forms.Textarea(attrs={"rows": 2, "cols": 60}),
        help_text="Contact information for the business (optional).",
    )
    common_expenses = forms.CharField(
        required=False,
        widget=forms.Textarea(
            attrs={
                "rows": 2,
                "cols": 60,
                "style": "min-height:60px;resize:vertical;width:100%;overflow:auto;",
            }
        ),
        help_text="",
    )
    custom_categories = forms.CharField(
        required=False,
        widget=forms.Textarea(
            attrs={
                "rows": 2,
                "cols": 60,
                "style": "min-height:60px;resize:vertical;width:100%;overflow:auto;",
            }
        ),
        help_text="",
    )
    industry_keywords = forms.CharField(
        required=False,
        widget=forms.Textarea(
            attrs={
                "rows": 2,
                "cols": 60,
                "style": "min-height:60px;resize:vertical;width:100%;overflow:auto;",
            }
        ),
        help_text="",
    )
    category_patterns = forms.CharField(
        required=False,
        widget=forms.Textarea(
            attrs={
                "rows": 2,
                "cols": 60,
                "style": "min-height:60px;resize:vertical;width:100%;overflow:auto;",
            }
        ),
        help_text="",
    )
    business_rules = forms.CharField(
        required=False,
        widget=forms.Textarea(
            attrs={
                "rows": 2,
                "cols": 60,
                "style": "min-height:60px;resize:vertical;width:100%;overflow:auto;",
            }
        ),
        help_text="",
    )

    class Meta:
        model = BusinessProfile
        fields = [
            "client_id",
            "contact_info",
            "business_description",
            "common_expenses",
            "custom_categories",
            "industry_keywords",
            "category_patterns",
            "business_rules",
        ]

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        for field in [
            "common_expenses",
            "custom_categories",
            "industry_keywords",
            "category_patterns",
            "business_rules",
        ]:
            val = getattr(self.instance, field, None)
            if val:
                if isinstance(val, dict):
                    val = ", ".join(f"{k}: {v}" for k, v in val.items())
                elif isinstance(val, list):
                    val = ", ".join(str(x) for x in val)
                elif isinstance(val, str):
                    val = val.replace("{", "").replace("}", "")
                    val = ", ".join([v.strip() for v in val.split(",") if v.strip()])
                # Ensure only one space after each comma (UI formatting)
                val = re.sub(r",\s*", ", ", val)
            else:
                val = ""
            self.fields[field].initial = val


class ClientFilter(admin.SimpleListFilter):
    title = _("client")
    parameter_name = "client"

    def lookups(self, request, model_admin):
        clients = set(Transaction.objects.values_list("client__client_id", flat=True))
        return [(client, client) for client in clients]

    def queryset(self, request, queryset):
        if self.value():
            return queryset.filter(client__client_id=self.value())
        return queryset


def call_agent(
    agent_name, transaction, model=None, max_retries=2, escalate_on_fail=True
):
    """Call the specified agent with the transaction data."""
    import os
    from openai import OpenAI

    logger = logging.getLogger(__name__)

    # --- START: NEW GUARDRAIL ---
    # For classification agents, if the amount is positive, it's income. No AI needed.
    agent = Agent.objects.get(name=agent_name)
    if "classification" in agent.purpose.lower() and transaction.amount > 0:
        logger.info(
            f"Transaction {transaction.id} has positive amount. Bypassing AI and auto-classifying as Income."
        )
        return {
            "classification_type": "Income",
            "worksheet": "Income",
            "category_name": "Client Income",
            "confidence": "high",
            "reasoning": "Auto-classified as Income due to positive transaction amount.",
            "business_percentage": 0,
            "questions": "",
            "proposed_category_name": "",
        }
    # --- END: NEW GUARDRAIL ---

    if model is None:
        model = os.environ.get("OPENAI_MODEL_PRECISE", "o4-mini")
    logger.info(f"Using OpenAI model: {model}")
    try:
        # Get the agent object from the database
        agent = Agent.objects.get(name=agent_name)
        base_url = agent.llm.url if agent.llm and agent.llm.url else None
        api_key = os.environ.get("OPENAI_API_KEY")
        # Use the LLMConfig.url as base_url if set, for multi-provider support
        if base_url:
            client = OpenAI(api_key=api_key, base_url=base_url)
        else:
            client = OpenAI(api_key=api_key)

        # Get the appropriate prompt based on agent type
        if "payee" in agent_name.lower():
            system_prompt = """You are a transaction analysis assistant. Your task is to:\n1. Identify the payee/merchant from transaction descriptions\n2. Use the search tool to gather comprehensive vendor information\n3. Synthesize all information into a clear, normalized description\n4. Return a final response in the exact JSON format specified\n\nIMPORTANT RULES:\n1. Make as many search calls as needed to gather complete information\n2. Synthesize all information into a clear, normalized response\n3. NEVER use the raw transaction description in your final response\n4. Format the response exactly as specified"""

            user_prompt = f"""Analyze this transaction and return a JSON object with EXACTLY these field names:\n{{\n    \"normalized_description\": \"string - A VERY SUCCINCT 2-5 word summary of what was purchased/paid for (e.g., 'Grocery shopping', 'Fast food purchase', 'Office supplies'). DO NOT include vendor details, just the core type of purchase.\",\n    \"payee\": \"string - The normalized payee/merchant name (e.g., 'Lowe's' not 'LOWE'S #1636', 'Walmart' not 'WALMART #1234')\",\n    \"confidence\": \"string - Must be exactly 'high', 'medium', or 'low'\",\n    \"reasoning\": \"string - VERBOSE explanation of the identification, including all search results and any details about the vendor, business type, and what was purchased. If you have a long description, put it here, NOT in normalized_description.\",\n    \"transaction_type\": \"string - One of: purchase, payment, transfer, fee, subscription, service\",\n    \"questions\": \"string - Any questions about unclear elements\",\n    \"needs_search\": \"boolean - Whether additional vendor information is needed\"\n}}\n\nTransaction: {transaction.description}\nAmount: ${transaction.amount}\nDate: {transaction.transaction_date}\n\nIMPORTANT INSTRUCTIONS:\n1. The 'normalized_description' MUST be a short phrase (2-5 words) summarizing the purchase type.\n2. Place any verbose or detailed explanation in the 'reasoning' field.\n3. NEVER use the raw transaction description in your final response.\n4. Include the type of business and what was purchased in the reasoning, not in normalized_description.\n5. Reference all search results used in the reasoning field.\n6. NEVER include store numbers, locations, or other non-standard elements in the payee field.\n7. Normalize the payee name to its standard business name (e.g., 'Lowe's' not 'LOWE'S #1636').\n8. ALWAYS provide a final JSON response after gathering all necessary information."""

        else:
            # Dynamically build allowed categories
            from profiles.models import (
                IRSExpenseCategory,
                IRSWorksheet,
                BusinessExpenseCategory,
            )

            # IRS categories (active, for all relevant worksheets)
            irs_cats = IRSExpenseCategory.objects.filter(
                is_active=True, worksheet__name__in=["6A", "Auto", "HomeOffice"]
            ).values("id", "name", "worksheet__name")
            # Business categories for this client
            biz_cats = BusinessExpenseCategory.objects.filter(
                is_active=True, business=transaction.client
            ).values("id", "category_name", "worksheet__name")
            # Build display list for prompt
            allowed_categories = []
            for cat in irs_cats:
                allowed_categories.append(
                    f"IRS-{cat['id']}: {cat['name']} (worksheet: {cat['worksheet__name']})"
                )
            for cat in biz_cats:
                allowed_categories.append(
                    f"BIZ-{cat['id']}: {cat['category_name']} (worksheet: {cat['worksheet__name']})"
                )
            allowed_categories.append("Other")  # Genuine catch-all
            allowed_categories.append("Personal")
            allowed_categories.append("Review")  # For LLM to flag for admin review
            # Build mapping for validation (not in prompt, but for post-processing)
            allowed_category_ids = set(
                [f"IRS-{cat['id']}" for cat in irs_cats]
                + [f"BIZ-{cat['id']}" for cat in biz_cats]
                + ["Other", "Personal", "Review"]
            )
            # Fetch business profile for the transaction's client
            business_profile = None
            try:
                business_profile = transaction.client
            except Exception:
                pass
            # Build business profile context string
            business_context_lines = []
            if business_profile:
                if business_profile.business_type:
                    business_context_lines.append(
                        f"Business Type: {business_profile.business_type}"
                    )
                if business_profile.business_description:
                    business_context_lines.append(
                        f"Business Description: {business_profile.business_description}"
                    )
                if business_profile.contact_info:
                    business_context_lines.append(
                        f"Contact Info: {business_profile.contact_info}"
                    )
                if business_profile.common_expenses:
                    business_context_lines.append(
                        f"Common Expenses: {business_profile.common_expenses}"
                    )
                if business_profile.custom_categories:
                    business_context_lines.append(
                        f"Custom Categories: {business_profile.custom_categories}"
                    )
                if business_profile.industry_keywords:
                    business_context_lines.append(
                        f"Industry Keywords: {business_profile.industry_keywords}"
                    )
                if business_profile.category_patterns:
                    business_context_lines.append(
                        f"Category Patterns: {business_profile.category_patterns}"
                    )
                if business_profile.business_rules:
                    business_context_lines.append(
                        f"Business Rules: {business_profile.business_rules}"
                    )
            business_context = "\n".join(business_context_lines)
            if business_context:
                business_context = f"Business Profile Context:\n{business_context}\n"
            else:
                business_context = ""
            # Add payee reasoning if available
            payee_reasoning = getattr(transaction, "payee_reasoning", None)
            if payee_reasoning:
                payee_context = (
                    f"Payee Reasoning (detailed vendor info):\n{payee_reasoning}\n"
                )
            else:
                payee_context = ""
            system_prompt = """You are an expert in business expense classification and tax preparation. Your role is to:\n1. Analyze transactions and determine if they are business or personal expenses\n2. For business expenses, determine the appropriate worksheet (6A, Vehicle, HomeOffice, or Personal)\n3. Provide detailed reasoning for your decisions\n4. Flag any transactions that need additional review\n\nConsider these factors:\n- Business type and description\n- Industry context\n- Transaction patterns\n- Amount and frequency\n- Business rules and patterns"""

            user_prompt = f"""{business_context}{payee_context}Return your analysis in this exact JSON format:\n{{\n    \"classification_type\": \"business\" or \"personal\",\n    \"worksheet\": \"6A\" or \"Vehicle\" or \"HomeOffice\" or \"Personal\",\n    \"category_id\": \"IRS-<id>\" or \"BIZ-<id>\" or \"Other\" or \"Personal\" or \"Review\",\n    \"category_name\": \"Name of the selected category from the list below\",\n    \"confidence\": \"high\" or \"medium\" or \"low\",\n    \"reasoning\": \"Detailed explanation of your decision, referencing both the business profile and payee reasoning above.\",\n    \"business_percentage\": \"integer - 0 for personal, 100 for clear business, 50 for dual-purpose, etc.\",\n    \"questions\": \"Any questions or uncertainties about this classification\",\n    \"proposed_category_name\": \"If you chose 'Review', propose a new category name that best fits the transaction. Otherwise, leave blank.\"\n}}\n\nTransaction: {transaction.description}\nAmount: ${transaction.amount}\nDate: {transaction.transaction_date}\n\nAllowed Categories (choose ONLY from this list):\n{chr(10).join(allowed_categories)}\n\nIMPORTANT RULES:\n- You MUST use one of the allowed category_id values above.\n- If the expense is business-related but does not fit any allowed category, use 'Review' and propose a new category name.\n- Only use 'Other' if it is a genuine, catch-all business category (e.g., 'Other Expenses', 'Miscellaneous', 'Check', 'Payment').\n- If the expense is not business-related, use 'Personal'.\n- NEVER invent a new category unless you use 'Review' and fill in 'proposed_category_name'.\n- For business expenses, use the most specific category that matches.\n- ALWAYS provide a business_percentage field as described above.\n- Use the payee reasoning above as additional context for your decision.\n\nIMPORTANT: Your response must be a valid JSON object."""

        # Prepare tools for the API call with proper schema
        tool_definitions = []
        for tool in agent.tools.all():
            tool_def = {
                "name": tool.name,
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "The search query to look up",
                            }
                        },
                        "required": ["query"],
                    },
                },
            }
            tool_definitions.append(tool_def)

        # Prepare the API request payload
        payload = {
            "model": agent.llm.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            "response_format": {"type": "json_object"},
        }

        # Only add tools and tool_choice if tools are available
        if tool_definitions:
            payload["tools"] = tool_definitions
            payload["tool_choice"] = "auto"

        # Log the complete API request
        logger.info("\n=== API Request ===")
        logger.info(f"Model: {agent.llm.model}")
        logger.info(f"System Prompt: {system_prompt}")
        logger.info(f"User Prompt: {user_prompt}")
        logger.info(f"Transaction: {transaction.description}")
        if tool_definitions:
            logger.info(f"Tools: {json.dumps(tool_definitions, indent=2)}")

        try:
            client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ]
            if tool_definitions:
                tools = tool_definitions
            else:
                tools = None
            max_tool_calls = 3
            tool_call_count = 0
            while True:
                payload = {
                    "model": agent.llm.model,
                    "messages": messages,
                    "response_format": {"type": "json_object"},
                }
                if tools:
                    payload["tools"] = tools
                    payload["tool_choice"] = "auto"
                response = client.chat.completions.create(**payload)
                logger.info(f"LLM response: {response}")
                msg = response.choices[0].message
                # If the LLM returns a tool call, append the assistant message and then the tool message(s)
                if hasattr(msg, "tool_calls") and msg.tool_calls:
                    if tool_call_count >= max_tool_calls:
                        messages.append(
                            {
                                "role": "user",
                                "content": "Maximum search limit reached. Now provide your final response in the exact JSON format specified.",
                            }
                        )
                        continue
                    # 1. Append the assistant message with tool_calls
                    messages.append(
                        {
                            "role": "assistant",
                            "content": None,
                            "tool_calls": [
                                (
                                    tc.to_dict()
                                    if hasattr(tc, "to_dict")
                                    else {
                                        "id": tc.id,
                                        "function": {
                                            "name": tc.function.name,
                                            "arguments": tc.function.arguments,
                                        },
                                        "type": "function",
                                    }
                                )
                                for tc in msg.tool_calls
                            ],
                        }
                    )
                    # 2. For each tool_call, execute and append a tool message
                    for tool_call in msg.tool_calls:
                        tool_name = tool_call.function.name
                        tool_args = json.loads(tool_call.function.arguments)
                        logger.info(
                            f"Executing tool: {tool_name} with args: {tool_args}"
                        )
                        try:
                            tool_obj = Tool.objects.get(name=tool_name)
                            module_path = tool_obj.module_path
                            module_name = module_path.split(".")[-1]
                            module = __import__(module_path, fromlist=[module_name])
                            if tool_name == "searxng_search":
                                tool_function = getattr(module, "searxng_search")
                            else:
                                tool_function = getattr(module, tool_name)
                            tool_result = tool_function(**tool_args)
                            logger.info(f"Tool result: {tool_result}")
                        except Exception as e:
                            logger.error(f"Error executing tool {tool_name}: {str(e)}")
                            raise
                        messages.append(
                            {
                                "role": "tool",
                                "tool_call_id": tool_call.id,
                                "name": tool_name,
                                "content": json.dumps(tool_result),
                            }
                        )
                        tool_call_count += 1
                    continue  # Loop again to get the next LLM response
                # If the LLM returns a final content message, parse and return it
                if msg.content:
                    return json.loads(msg.content)
                logger.error(
                    "LLM returned neither tool_calls nor content. Breaking loop."
                )
                break
            raise RuntimeError("Failed to get a valid response from the LLM.")

        except Exception as e:
            logger.error(f"Error calling OpenAI API: {str(e)}")
            raise

    except Exception as e:
        logger.error(f"Error in call_agent: {str(e)}")
        raise


def process_transactions(modeladmin, request, queryset):
    if "agent" not in request.POST:
        # Show the agent selection form
        agents = Agent.objects.all().order_by("name")  # Order agents by name
        if not agents:
            messages.error(
                request, "No agents available. Please create an agent first."
            )
            return HttpResponseRedirect(request.get_full_path())

        return render(
            request,
            "admin/process_transactions.html",
            context={
                "transactions": queryset,
                "agents": agents,
                "title": "Select Agent to Process Transactions",
                "opts": modeladmin.model._meta,
            },
        )

    # Process the transactions with the selected agent
    agent_id = request.POST["agent"]
    try:
        agent = Agent.objects.get(id=agent_id)
        for transaction in queryset:
            response = call_agent(agent.name, transaction)
            update_fields = get_update_fields_from_response(
                agent,
                response,
                (
                    getattr(agent, "purpose", "").lower()
                    if hasattr(agent, "purpose")
                    else "classification"
                ),
            )
            logger.info(
                f"Update fields for transaction {transaction.id}: {update_fields}"
            )
            rows_updated = Transaction.objects.filter(id=transaction.id).update(
                **update_fields
            )
            logger.info(f"Updated {rows_updated} rows for transaction {transaction.id}")
            updated_tx = Transaction.objects.get(id=transaction.id)
            logger.info(
                f"Transaction {transaction.id} after update: payee={updated_tx.payee}, classification_type={updated_tx.classification_type}, worksheet={updated_tx.worksheet}, confidence={updated_tx.confidence}, category={updated_tx.category}"
            )
        messages.success(
            request,
            f"Successfully processed {queryset.count()} transactions with {agent.name}",
        )
    except Agent.DoesNotExist:
        messages.error(request, "Selected agent not found")
    except Exception as e:
        messages.error(request, f"Error processing transactions: {str(e)}")
    return HttpResponseRedirect(request.get_full_path())


process_transactions.short_description = "Process selected transactions with agent"


def reset_processing_status(modeladmin, request, queryset):
    """Reset selected transactions to 'Not Processed' status."""
    updated = queryset.update(
        payee_extraction_method="None",
        classification_method="None",
        payee=None,
        normalized_description=None,
        confidence=None,
        reasoning=None,
        payee_reasoning=None,
        business_context=None,
        questions=None,
        classification_type=None,
        worksheet=None,
        business_percentage=None,
        category=None,
    )
    messages.success(
        request, f"Successfully reset {updated} transactions to 'Not Processed' status."
    )


reset_processing_status.short_description = (
    "Reset selected transactions to 'Not Processed'"
)


class TransactionAdminForm(forms.ModelForm):
    notes = forms.CharField(
        required=False,
        widget=forms.Textarea(
            attrs={
                "rows": 2,
                "cols": 60,
                "style": "min-height:40px;resize:vertical;width:100%;overflow:auto;",
            }
        ),
        label="Notes",
        help_text="Optional: Add any additional notes or context for this transaction (for bookkeeper use).",
    )
    # Explicitly define as ChoiceField to force dropdown rendering in admin
    category = forms.ChoiceField(
        choices=[],  # Will be set dynamically in __init__
        required=False,
        label="Category",
    )
    classification_type = forms.ChoiceField(
        choices=[],  # Will be set dynamically in __init__
        required=False,
        label="Classification Type",
    )
    CLASSIFICATION_TYPE_CHOICES = [
        ("business", "Business"),
        ("personal", "Personal"),
    ]

    def _get_category_choices(self, current_value=None):
        irs_cats = IRSExpenseCategory.objects.filter(
            worksheet__name="6A", is_active=True
        ).order_by("line_number")
        irs_choices = [(cat.name, f"IRS: {cat.name}") for cat in irs_cats]
        biz_cats = BusinessExpenseCategory.objects.filter(
            worksheet__name="6A", is_active=True
        ).order_by("category_name")
        biz_choices = [
            (cat.category_name, f"Business: {cat.category_name}") for cat in biz_cats
        ]
        personal_choice = [("Personal", "--- Personal ---")]
        choices = irs_choices + biz_choices + personal_choice
        if not choices:
            choices = [("", "--- No categories available ---")]
        if current_value and current_value not in [c[0] for c in choices]:
            choices = [(current_value, f"Current: {current_value}")] + choices
        return choices

    def _get_classification_type_choices(self, current_value=None):
        choices = self.CLASSIFICATION_TYPE_CHOICES.copy()
        if not choices:
            choices = [("", "--- No types available ---")]
        if current_value and current_value not in [c[0] for c in choices]:
            choices = [(current_value, f"Current: {current_value}")] + choices
        return choices

    class Meta:
        model = Transaction
        fields = "__all__"
        widgets = {
            "business_percentage": forms.NumberInput(attrs={"min": 0, "max": 100}),
            "confidence": forms.Select(
                choices=[("high", "high"), ("medium", "medium"), ("low", "low")]
            ),
        }

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.fields["notes"].initial = self.instance.business_context
        # Set dynamic choices for category and classification_type
        current_category = self.instance.category
        current_classification = self.instance.classification_type
        self.fields["category"].choices = self._get_category_choices(current_category)
        self.fields["classification_type"].choices = (
            self._get_classification_type_choices(current_classification)
        )
        # Make classification_method readonly (never user-editable)
        if "classification_method" in self.fields:
            self.fields["classification_method"].disabled = True

    def clean_category(self):
        # Only save the value, not the label
        return self.cleaned_data["category"]

    def save(self, commit=True):
        instance = super().save(commit=False)
        # Save notes back to business_context
        instance.business_context = self.cleaned_data.get("notes", "")
        # Always set classification_method to 'None' if saving via admin form
        instance.classification_method = "None"
        if commit:
            instance.save()
        return instance


# Add a ProcessedFilter for sidebar
class ProcessedFilter(admin.SimpleListFilter):
    title = _("Processed")
    parameter_name = "processed"

    def lookups(self, request, model_admin):
        return (
            ("yes", _("Processed")),
            ("no", _("Unprocessed")),
        )

    def queryset(self, request, queryset):
        if self.value() == "yes":
            return queryset.exclude(classification_method__isnull=True).exclude(
                classification_method="None"
            )
        if self.value() == "no":
            return queryset.filter(
                classification_method__isnull=True
            ) | queryset.filter(classification_method="None")
        return queryset


class NeedsAccountNumberFilter(admin.SimpleListFilter):
    title = _("Needs Account Number")
    parameter_name = "needs_account_number"

    def lookups(self, request, model_admin):
        return (
            ("yes", _("Needs Account Number")),
            ("no", _("Has Account Number")),
        )

    def queryset(self, request, queryset):
        if self.value() == "yes":
            return queryset.filter(needs_account_number=True)
        if self.value() == "no":
            return queryset.filter(needs_account_number=False)
        return queryset


# Comment out all admin registrations to debug recursion error
# @admin.register(Transaction)
# class TransactionAdmin(admin.ModelAdmin):
#     form = TransactionAdminForm
#     list_display = (
#         "transaction_date",
#         "amount",
#         "description",
#         "normalized_description",
#         "payee",
#         "category",
#         "classification_type",
#         "worksheet",
#         "business_percentage",
#         "confidence",
#         "source",
#         "file_link_column",
#         "account_number",
#         "short_reasoning",  # Use icon if present
#         "short_payee_reasoning",  # Use icon if present
#         "classification_method",
#         "payee_extraction_method",
#     )
#     list_filter = (
#         ClientFilter,
#         ProcessedFilter,
#         NeedsAccountNumberFilter,  # Add our new filter
#         "transaction_date",
#         "classification_type",
#         "worksheet",
#         "confidence",
#         "category",
#         "source",
#         "transaction_type",
#         "classification_method",
#         "payee_extraction_method",
#     )
#     search_fields = (
#         "description",
#         "normalized_description",
#         "category",
#         "source",
#         "transaction_type",
#         "account_number",
#         "payee",
#         "reasoning",
#         "payee_reasoning",
#         "business_context",
#         "questions",
#         "classification_type",
#         "worksheet",
#     )
#     readonly_fields = (
#         "transaction_date",
#         "amount",
#         "description",
#         "normalized_description",
#         "payee",
#         "worksheet",
#         "payee_extraction_method",
#         "reasoning",
#         "payee_reasoning",
#         "classification_method",  # Always readonly
#     )
#     # Remove 'business_context' from readonly, add 'notes' as editable
#     fieldsets = (
#         (
#             None,
#             {
#                 "fields": (
#                     "transaction_date",
#                     "amount",
#                     "description",
#                     "normalized_description",
#                     "payee",
#                     "category",
#                     "classification_type",
#                     "worksheet",
#                     "business_percentage",
#                     "confidence",
#                     "classification_method",
#                     "payee_extraction_method",
#                     "reasoning",
#                     "payee_reasoning",
#                     "notes",
#                 )
#             },
#         ),
#     )
#     actions = [
#         "reset_processing_status",
#         "batch_payee_lookup",
#         "batch_classify",
#         "mark_as_personal",
#         "mark_as_business",
#         "mark_as_unclassified",
#         "batch_set_account_number",  # New batch action
#     ]

#     def short_reasoning(self, obj):
#         if obj.reasoning:
#             return format_html('<span title="{}">🛈</span>', obj.reasoning)
#         return ""

#     short_reasoning.short_description = "Reasoning"

#     def short_payee_reasoning(self, obj):
#         if obj.payee_reasoning:
#             return format_html('<span title="{}">🛈</span>', obj.payee_reasoning)
#         return ""

#     short_payee_reasoning.short_description = "Payee Reasoning"

#     def file_link_column(self, obj):
#         if obj.statement_file:
#             filename = obj.statement_file.original_filename or os.path.basename(
#                 obj.statement_file.file.name
#             )
#             # Use the new download view for all files to ensure consistency
#             url = reverse(
#                 "reports:download_statement_file", args=[obj.statement_file.id]
#             )
#             return format_html('<a href="{}" target="_blank">{}</a>', url, filename)
#         return "-"

#     file_link_column.short_description = "Original File"
#     file_link_column.admin_order_field = "file_path"

#     @admin.action(description="Batch set account number for selected transactions")
#     def batch_set_account_number(self, request, queryset):
#         from django import forms

#         class AccountNumberForm(forms.Form):
#             account_number = forms.CharField(label="Account Number", required=True)

#         if "apply" in request.POST:
#             form = AccountNumberForm(request.POST)
#             if form.is_valid():
#                 account_number = form.cleaned_data["account_number"]
#                 updated = queryset.update(
#                     account_number=account_number, needs_account_number=False
#                 )
#                 self.message_user(
#                     request, f"Set account number for {updated} transactions."
#                 )
#                 return
#         else:
#             form = AccountNumberForm()
#         return render(
#             request,
#             "admin/batch_set_account_number.html",
#             {"form": form, "queryset": queryset},
#         )

#     def batch_payee_lookup(self, request, queryset):
#         """Create a batch processing task for payee lookup."""
#         if not queryset:
#             messages.error(request, "No transactions selected.")
#             return

#         # Group transactions by client
#         client_transactions = {}
#         for transaction in queryset:
#             if transaction.client_id not in client_transactions:
#                 client_transactions[transaction.client_id] = {
#                     "client": transaction.client,
#                     "transactions": [],
#                     "transaction_ids": [],
#                 }
#             client_transactions[transaction.client_id]["transactions"].append(
#                 transaction
#             )
#             client_transactions[transaction.client_id]["transaction_ids"].append(
#                 transaction.id
#             )

#         # Create a task for each client's transactions
#         for client_id, data in client_transactions.items():
#             with db_transaction.atomic():
#                 task = ProcessingTask.objects.create(
#                     task_type="payee_lookup",
#                     client=data["client"],
#                     transaction_count=len(data["transactions"]),
#                     status="pending",
#                     task_metadata={
#                         "description": f"Batch payee lookup for {len(data['transactions'])} transactions"
#                     },
#                 )
#                 task.transactions.add(*data["transaction_ids"])
#                 messages.success(
#                     request,
#                     f"Created payee lookup task for client {client_id} with {len(data['transactions'])} transactions",
#                 )

#     batch_payee_lookup.short_description = "Create batch payee lookup task"

#     def batch_classify(self, request, queryset):
#         """Create a batch processing task for classification."""
#         if not queryset:
#             messages.error(request, "No transactions selected.")
#             return

#         # Group transactions by client
#         client_transactions = {}
#         for transaction in queryset:
#             if transaction.client_id not in client_transactions:
#                 client_transactions[transaction.client_id] = {
#                     "client": transaction.client,
#                     "transactions": [],
#                     "transaction_ids": [],
#                 }
#             client_transactions[transaction.client_id]["transactions"].append(
#                 transaction
#             )
#             client_transactions[transaction.client_id]["transaction_ids"].append(
#                 transaction.id
#             )

#         # Create a task for each client's transactions
#         for client_id, data in client_transactions.items():
#             with db_transaction.atomic():
#                 task = ProcessingTask.objects.create(
#                     task_type="classification",
#                     client=data["client"],
#                     transaction_count=len(data["transactions"]),
#                     status="pending",
#                     task_metadata={
#                         "description": f"Batch classification for {len(data['transactions'])} transactions"
#                     },
#                 )
#                 task.transactions.add(*data["transaction_ids"])
#                 messages.success(
#                     request,
#                     f"Created classification task for client {client_id} with {len(data['transactions'])} transactions",
#                 )

#     batch_classify.short_description = "Create batch classification task"

#     def mark_as_personal(self, request, queryset):
#         updated = queryset.update(
#             classification_type="personal",
#             worksheet="Personal",
#             category="Personal",
#         )
#         self.message_user(request, f"Marked {updated} transactions as Personal.")

#     mark_as_personal.short_description = "Mark selected as Personal"

#     def mark_as_business(self, request, queryset):
#         from .models import IRSExpenseCategory, BusinessExpenseCategory, IRSWorksheet

#         count = 0
#         worksheet = IRSWorksheet.objects.filter(name="6A").first()
#         for tx in queryset:
#             # Set as business, worksheet 6A
#             tx.classification_type = "business"
#             tx.worksheet = "6A"
#             tx.save(update_fields=["classification_type", "worksheet"])
#             # Check if category is in IRS 6A or user-defined
#             cat_name = tx.category
#             if not IRSExpenseCategory.objects.filter(
#                 worksheet=worksheet, name=cat_name
#             ).exists():
#                 # Not an official IRS category, check if user-defined exists
#                 if not BusinessExpenseCategory.objects.filter(
#                     business=tx.client, worksheet=worksheet, category_name=cat_name
#                 ).exists():
#                     # Auto-add user-defined business category
#                     BusinessExpenseCategory.objects.create(
#                         business=tx.client,
#                         worksheet=worksheet,
#                         category_name=cat_name,
#                         is_active=True,
#                     )
#             count += 1
#         self.message_user(
#             request,
#             f"Marked {count} transactions as Business and auto-added categories as needed.",
#         )

#     mark_as_business.short_description = (
#         "Mark selected as Business (auto-add category if needed)"
#     )

#     def mark_as_unclassified(self, request, queryset):
#         updated = queryset.update(
#             classification_method=CLASSIFICATION_METHOD_UNCLASSIFIED,
#             classification_type=None,
#             worksheet=None,
#             category=None,
#             confidence=None,
#             reasoning=None,
#             business_percentage=None,
#         )
#         self.message_user(request, f"Marked {updated} transactions as Unclassified.")

#     mark_as_unclassified.short_description = (
#         "Mark selected as Unclassified (reset classification only)"
#     )

#     def get_actions(self, request):
#         actions = super().get_actions(request)
#         # Remove Business Profile Generator from actions
#         actions = {
#             k: v for k, v in actions.items() if "business_profile_generator" not in k
#         }
#         # Keep existing agent-specific actions
#         for agent in Agent.objects.all():
#             action_name = f'process_with_{agent.name.lower().replace(" ", "_")}'
#             if "business_profile_generator" in action_name:
#                 continue
#             action_function = self._create_agent_action(agent)
#             action_function.short_description = f"Process with {agent.name}"
#             actions[action_name] = (
#                 action_function,
#                 action_name,
#                 action_function.short_description,
#             )
#         return actions

#     def _create_agent_action(self, agent):
#         def process_with_agent(modeladmin, request, queryset):
#             try:
#                 for transaction in queryset:
#                     logger.info(
#                         f"Processing transaction {transaction.id} with agent {agent.name}"
#                     )
#                     response = call_agent(agent.name, transaction)
#                     logger.info(f"Agent response: {response}")
#                     update_fields = get_update_fields_from_response(
#                         agent,
#                         response,
#                         (
#                             getattr(agent, "purpose", "").lower()
#                             if hasattr(agent, "purpose")
#                             else "classification"
#                         ),
#                     )
#                     logger.info(
#                         f"Update fields for transaction {transaction.id}: {update_fields}"
#                     )
#                     rows_updated = Transaction.objects.filter(id=transaction.id).update(
#                         **update_fields
#                     )
#                     logger.info(
#                         f"Updated {rows_updated} rows for transaction {transaction.id}"
#                     )
#                     updated_tx = Transaction.objects.get(id=transaction.id)
#                     logger.info(
#                         f"Transaction {transaction.id} after update: payee={updated_tx.payee}, classification_type={updated_tx.classification_type}, worksheet={updated_tx.worksheet}, confidence={updated_tx.confidence}, category={updated_tx.category}"
#                     )
#                 messages.success(
#                     request,
#                     f"Successfully processed {queryset.count()} transactions with {agent.name}",
#                 )
#             except Exception as e:
#                 logger.error(
#                     f"Error processing transactions with {agent.name}: {str(e)}",
#                     exc_info=True,
#                 )
#                 messages.error(
#                     request,
#                     f"Error processing transactions with {agent.name}: {str(e)}",
#                 )

#         return process_with_agent

#     def changeform_view(self, request, object_id=None, form_url="", extra_context=None):
#         # Remove 'Save and add another' and relabel 'Save and continue editing' to 'Save'
#         extra_context = extra_context or {}
#         extra_context["show_save_and_add_another"] = False
#         extra_context["show_save_and_continue"] = True
#         extra_context["save_as_continue"] = False
#         extra_context["save_as"] = False
#         extra_context["save_continue_label"] = "Save"
#         return super().changeform_view(
#             request, object_id, form_url, extra_context=extra_context
#         )


# @admin.register(LLMConfig)
# class LLMConfigAdmin(admin.ModelAdmin):
#     list_display = ("provider", "model", "url")
#     search_fields = ("provider", "model")
#     exclude = ("id",)  # Prevent manual id entry in admin


# @admin.register(Agent)
# class AgentAdmin(admin.ModelAdmin):
#     list_display = ("name", "purpose", "llm")
#     search_fields = ("name", "purpose", "llm__name")
#     filter_horizontal = ("tools",)


# @admin.register(Tool)
# class ToolAdmin(admin.ModelAdmin):
#     list_display = ("name", "description", "module_path")
#     search_fields = ("name", "description", "module_path")


# @admin.register(IRSExpenseCategory)
# class IRSExpenseCategoryAdmin(admin.ModelAdmin):
#     list_display = ("name", "worksheet", "line_number", "is_active")
#     search_fields = ("name", "description", "line_number")
#     list_filter = ("worksheet", "is_active")
#     ordering = ("worksheet", "line_number")


# @admin.register(BusinessExpenseCategory)
# class BusinessExpenseCategoryAdmin(admin.ModelAdmin):
#     list_display = (
#         "category_name",
#         "business",
#         "worksheet",
#         "parent_category",
#         "is_active",
#     )
#     search_fields = ("category_name", "description")
#     list_filter = ("business", "worksheet", "is_active", "tax_year")
#     ordering = ("business", "category_name")


# @admin.register(ProcessingTask)
# class ProcessingTaskAdmin(admin.ModelAdmin):
#     list_display = (
#         "task_id",
#         "task_type",
#         "client",
#         "status_with_progress",
#         "transaction_count",
#         "processed_count",
#         "error_count",
#         "created_at",
#         "updated_at",
#     )
#     list_filter = (
#         "task_type",
#         "status",
#         "client",
#         "created_at",
#         "updated_at",
#     )
#     search_fields = (
#         "task_id",
#         "client__client_id",
#         "error_details",
#         "task_metadata",
#     )
#     readonly_fields = (
#         "task_id",
#         "task_type",
#         "client",
#         "status",
#         "transaction_count",
#         "processed_count",
#         "error_count",
#         "created_at",
#         "updated_at",
#         "error_details",
#         "task_metadata",
#     )
#     actions = ["retry_failed_tasks", "cancel_tasks", "run_task"]

#     def change_view(self, request, object_id, form_url="", extra_context=None):
#         extra_context = extra_context or {}
#         task = self.get_object(request, object_id)
#         # Always read-only
#         extra_context["hide_save"] = True
#         # Auto-refresh if running
#         if task and task.status in ["pending", "processing"]:
#             extra_context["auto_refresh"] = True
#         # Add log viewer if log file exists
#         import os
#         from django.conf import settings
#         from pathlib import Path

#         log_file = Path(settings.BASE_DIR) / "logs" / f"task_{task.task_id}.log"
#         if log_file.exists():
#             try:
#                 with open(log_file, "r") as f:
#                     lines = f.readlines()[-100:]
#                 log_content = mark_safe(
#                     '<pre style="max-height:300px;overflow:auto;background:#222;color:#eee;padding:10px;">{}</pre>'.format(
#                         "".join(lines)
#                     )
#                 )
#                 extra_context["log_content"] = log_content
#             except Exception:
#                 extra_context["log_content"] = mark_safe(
#                     '<pre style="color:red;">Error reading log file.</pre>'
#                 )
#         else:
#             extra_context["log_content"] = mark_safe(
#                 '<pre style="color:#888;">No log file found for this task.</pre>'
#             )
#         return super().change_view(
#             request, object_id, form_url, extra_context=extra_context
#         )

#     def run_task(self, request, queryset):
#         """Execute the selected task and show progress."""
#         if queryset.count() > 1:
#             messages.error(request, "Please select only one task to run at a time.")
#             return

#         task = queryset.first()
#         if task.status != "pending":
#             messages.error(request, f"Task {task.task_id} is not in pending state.")
#             return

#         # Create log file first
#         log_file = Path(settings.BASE_DIR) / "logs" / f"task_{task.task_id}.log"
#         log_file.parent.mkdir(exist_ok=True)
#         with open(log_file, "w") as f:
#             f.write(f"[{timezone.now()}] [INFO] Starting task {task.task_id}\n")

#         try:
#             # Verify the task exists and is in pending state
#             task.refresh_from_db()
#             if task.status != "pending":
#                 messages.error(request, f"Task {task.task_id} is not in pending state.")
#                 return

#             # Update task status to processing and commit it
#             with db_transaction.atomic():
#                 task.status = "processing"
#                 task.started_at = timezone.now()
#                 task.save(force_update=True)

#             # Start the task processing command
#             python_executable = sys.executable
#             # Always use the manage.py in the LedgerFlow project root
#             manage_py = str(Path(settings.BASE_DIR) / "manage.py")
#             cmd = [
#                 python_executable,
#                 manage_py,
#                 "process_task",
#                 str(task.task_id),
#                 "--log-file",
#                 str(log_file),
#             ]

#             # Set up environment variables
#             env = os.environ.copy()
#             project_root = str(Path(settings.BASE_DIR).parent)
#             env["PYTHONPATH"] = f"{project_root}:{env.get('PYTHONPATH', '')}"
#             env["DJANGO_SETTINGS_MODULE"] = "ledgerflow.settings"

#             # Start the process in the background
#             process = subprocess.Popen(
#                 cmd,
#                 env=env,
#                 cwd=str(settings.BASE_DIR),
#                 stdout=subprocess.PIPE,
#                 stderr=subprocess.PIPE,
#                 universal_newlines=True,
#                 start_new_session=True,
#                 bufsize=1,
#             )

#             # Log the process start
#             logger.info(f"Started task {task.task_id} with PID {process.pid}")
#             self.message_user(request, f"Started task {task.task_id}")

#             # Start a thread to read the output
#             def read_output():
#                 while True:
#                     output = process.stdout.readline()
#                     if output == "" and process.poll() is not None:
#                         break
#                     if output:
#                         logger.info(output.strip())
#                         with open(log_file, "a") as f:
#                             f.write(output)

#             import threading

#             output_thread = threading.Thread(target=read_output)
#             output_thread.daemon = True
#             output_thread.start()

#             # Start a thread to read errors
#             def read_errors():
#                 while True:
#                     error = process.stderr.readline()
#                     if error == "" and process.poll() is not None:
#                         break
#                     if error:
#                         logger.error(error.strip())
#                         with open(log_file, "a") as f:
#                             f.write(f"[ERROR] {error}")

#             error_thread = threading.Thread(target=read_errors)
#             error_thread.daemon = True
#             error_thread.start()

#             # Wait for the process to complete
#             def wait_for_process():
#                 process.wait()
#                 if process.returncode != 0:
#                     logger.error(
#                         f"Task {task.task_id} failed with return code {process.returncode}"
#                     )
#                     # Update task status to failed if the process failed
#                     task.refresh_from_db()
#                     if task.status == "processing":
#                         task.status = "failed"
#                         task.error_details = {
#                             "error": f"Process failed with return code {process.returncode}"
#                         }
#                         task.save(force_update=True)

#             # Start the wait thread
#             wait_thread = threading.Thread(target=wait_for_process)
#             wait_thread.daemon = True
#             wait_thread.start()

#         except Exception as e:
#             logger.error(f"Failed to start task {task.task_id}: {str(e)}")
#             task.status = "failed"
#             task.error_details = {"error": str(e)}
#             task.save(force_update=True)
#             self.message_user(
#                 request, f"Failed to start task: {str(e)}", level=messages.ERROR
#             )

#     run_task.short_description = "Run selected task"

#     def retry_failed_tasks(self, request, queryset):
#         """Retry failed processing tasks."""
#         for task in queryset.filter(status="failed"):
#             task.status = "pending"
#             task.error_count = 0
#             task.error_details = {}
#             task.save()
#             messages.success(request, f"Retrying task {task.task_id}")
#         messages.success(
#             request, f"Retried {queryset.filter(status='failed').count()} failed tasks"
#         )

#     retry_failed_tasks.short_description = "Retry failed tasks"

#     def cancel_tasks(self, request, queryset):
#         """Cancel selected processing tasks."""
#         for task in queryset.filter(status__in=["pending", "processing"]):
#             task.status = "failed"
#             task.error_details = {
#                 "cancelled": True,
#                 "cancelled_at": str(datetime.now()),
#             }
#             task.save()
#             messages.success(request, f"Cancelled task {task.task_id}")
#         messages.success(
#             request,
#             f"Cancelled {queryset.filter(status__in=['pending', 'processing']).count()} tasks",
#         )

#     cancel_tasks.short_description = "Cancel selected tasks"

#     def view_task_transactions(self, request, task_id):
#         """View transactions associated with a processing task."""
#         task = get_object_or_404(ProcessingTask, task_id=task_id)
#         transactions = task.transactions.all()
#         return render(
#             request,
#             "admin/processing_task_transactions.html",
#             context={
#                 "task": task,
#                 "transactions": transactions,
#                 "title": f"Transactions for Task {task_id}",
#                 "opts": self.model._meta,
#             },
#         )

#     def status_with_progress(self, obj):
#         # Status badge
#         status = obj.status
#         badge_map = {
#             "pending": ("⏳ Pending", "background:#f6c23e;color:#fff;"),
#             "processing": ("🔄 Processing", "background:#36b9cc;color:#fff;"),
#             "completed": ("✅ Completed", "background:#1cc88a;color:#fff;"),
#             "failed": ("❌ Failed", "background:#e74a3b;color:#fff;"),
#         }
#         label, style = badge_map.get(status, (status.title(), ""))
#         badge_html = f'<span style="font-weight:bold;padding:0.2em 0.7em;border-radius:1em;{style}font-size:0.95em;display:inline-block;margin-right:0.5em;min-width:80px;white-space:nowrap;">{label}</span>'
#         # Progress bar for processing
#         progress_html = ""
#         if status == "processing":
#             processed = obj.processed_count or 0
#             total = obj.transaction_count or 0
#             percent = int((processed / total) * 100) if total > 0 else 0
#             progress_html = f"""
#                 <div style="border-radius:3px;overflow:hidden;background:#f0f0f0;border:1px solid #ccc;height:20px;width:200px;margin-top:5px;">
#                   <div style="background:#79aec8;height:100%;width:{percent}%;transition:width 0.3s ease;"></div>
#                 </div>
#                 <div style="font-size:12px;color:#666;margin-top:2px;">{processed} / {total}</div>
#             """
#         return mark_safe(badge_html + progress_html)

#     status_with_progress.short_description = "Status"
#     status_with_progress.allow_tags = True


# # Restore the original StatementFileAdminForm for single-file upload
# class StatementFileAdminForm(forms.ModelForm):
#     file = forms.FileField(
#         widget=forms.ClearableFileInput(), required=True, label="Upload File"
#     )

#     class Meta:
#         model = StatementFile
#         fields = [
#             "client",
#             "file",
#             "file_type",
#             "bank",
#             "account_number",
#             "year",
#             "month",
#             "status",
#             "status_detail",
#         ]


# def get_parser_module_choices():
#     try:
#         sys.path.append("/Users/greg/repos/LedgerFlow_AI/PDF-extractor")
#         from dataextractai.parsers_core.autodiscover import autodiscover_parsers

#         autodiscover_parsers()
#         registry_mod = importlib.import_module("dataextractai.parsers_core.registry")
#         registry = getattr(registry_mod, "ParserRegistry")
#         parser_names = list(getattr(registry, "_parsers", {}).keys())
#         # Add 'autodetect' as the default option
#         return [("autodetect", "Autodetect (Recommended)")] + [
#             (name, name) for name in parser_names
#         ]
#     except Exception as e:
#         print(f"[DEBUG] Exception in get_parser_module_choices: {e}")
#         import traceback

#         traceback.print_exc()
#         return [("autodetect", "Autodetect (Recommended)")]


# # Restore the batch uploader form (no multiple=True in widget)
# class BatchStatementFileUploadForm(forms.Form):
#     client = forms.ModelChoiceField(
#         queryset=BusinessProfile.objects.all(), required=True
#     )
#     file_type = forms.ChoiceField(
#         choices=StatementFile._meta.get_field("file_type").choices, required=True
#     )
#     parser_module = forms.ChoiceField(
#         choices=[], required=False, label="Parser Module (optional)"
#     )
#     account_number = forms.CharField(label="Account Number (optional)", required=False)
#     auto_parse = forms.BooleanField(
#         label="Auto-parse and create transactions on upload",
#         required=False,
#         initial=True,
#     )

#     def __init__(self, *args, **kwargs):
#         super().__init__(*args, **kwargs)
#         self.fields["parser_module"].choices = get_parser_module_choices()


# @admin.register(StatementFile)
# class StatementFileAdmin(admin.ModelAdmin):
#     form = StatementFileAdminForm
#     list_display = (
#         "client_name_column",
#         "original_filename_link",
#         "file_type",
#         "source_column",
#         "status",
#         "upload_timestamp",
#         "uploaded_by",
#         "bank",
#         "account_number",
#         "account_holder_name",
#         "address",
#         "account_type",
#         "statement_period_start",
#         "statement_period_end",
#         "statement_date",
#         "year",
#         "month",
#         "extra_metadata_column",
#         "status_detail",
#     )
#     list_filter = (
#         "client",
#         "file_type",
#         "parser_module",
#         "status",
#         "year",
#         "month",
#         "bank",
#         NeedsAccountNumberFilter,
#     )
#     search_fields = (
#         "original_filename",
#         "bank",
#         "account_number",
#         "account_holder_name",
#         "address",
#         "status_detail",
#     )
#     readonly_fields = (
#         "upload_timestamp",
#         "uploaded_by",
#         "parsed_metadata",
#         "parser_module",
#         "file_link",
#         "bank",
#         "account_number",
#         "account_holder_name",
#         "address",
#         "account_type",
#         "statement_period_start",
#         "statement_period_end",
#         "statement_date",
#         "year",
#         "month",
#         "status_detail",
#     )
#     fieldsets = (
#         (
#             None,
#             {
#                 "fields": [
#                     "client",
#                     "file",
#                     "file_type",
#                     "parser_module",
#                     "status",
#                     "status_detail",
#                     "bank",
#                     "account_number",
#                     "account_holder_name",
#                     "address",
#                     "account_type",
#                     "statement_period_start",
#                     "statement_period_end",
#                     "statement_date",
#                     "year",
#                     "month",
#                     "upload_timestamp",
#                     "uploaded_by",
#                     "parsed_metadata",
#                     "file_link",
#                 ]
#             },
#         ),
#     )
#     actions = [
#         "batch_set_account_number",
#     ]

#     def source_column(self, obj):
#         return obj.parser_module

#     source_column.short_description = "Source"
#     source_column.admin_order_field = "parser_module"

#     def client_name_column(self, obj):
#         return obj.client.client_id if obj.client else "-"

#     client_name_column.short_description = "Client"
#     client_name_column.admin_order_field = "client__client_id"

#     def extra_metadata_column(self, obj):
#         extra = obj.parsed_metadata or getattr(obj, "extra", None)
#         if extra and isinstance(extra, dict) and extra:
#             # Compact JSON for title attribute (browser tooltip)
#             tooltip = json.dumps(extra, separators=(",", ": "))
#             return format_html(
#                 '<span title="{}" style="cursor:pointer;">&#9776;</span>', tooltip
#             )
#         return ""

#     extra_metadata_column.short_description = "Extra Metadata"
#     extra_metadata_column.allow_tags = True

#     def original_filename_link(self, obj):
#         if obj.file:
#             return format_html(
#                 '<a href="{}" target="_blank">{}</a>',
#                 obj.file.url,
#                 obj.original_filename,
#             )
#         return obj.original_filename or "-"

#     original_filename_link.short_description = "Original Filename"
#     original_filename_link.admin_order_field = "original_filename"

#     def file_link(self, obj):
#         if obj.file and hasattr(obj.file, "url"):
#             return format_html(
#                 '<a href="{}" target="_blank">{}</a>', obj.file.url, obj.file.name
#             )
#         return "No file uploaded"

#     file_link.short_description = "File Download Link"

#     @admin.action(description="Batch set account number for selected statement files")
#     def batch_set_account_number(self, request, queryset):
#         from django import forms

#         class AccountNumberForm(forms.Form):
#             account_number = forms.CharField(label="Account Number", required=True)

#         if "apply" in request.POST:
#             form = AccountNumberForm(request.POST)
#             if form.is_valid():
#                 account_number = form.cleaned_data["account_number"]
#                 updated = queryset.update(
#                     account_number=account_number, needs_account_number=False
#                 )
#                 self.message_user(
#                     request, f"Set account number for {updated} statement files."
#                 )
#                 return
#         else:
#             form = AccountNumberForm()
#         return render(
#             request,
#             "admin/batch_set_account_number.html",
#             {"form": form, "queryset": queryset},
#         )

#     def changelist_view(self, request, extra_context=None):
#         extra_context = extra_context or {}
#         from django.urls import reverse

#         extra_context["batch_upload_url"] = reverse(
#             "admin:profiles_statementfile_batch_upload"
#         )
#         return super().changelist_view(request, extra_context=extra_context)

#     def batch_upload_view(self, request):
#         if request.method == "POST":
#             form = BatchStatementFileUploadForm(request.POST, request.FILES)
#             if form.is_valid():
#                 client = form.cleaned_data["client"]
#                 file_type = form.cleaned_data["file_type"]
#                 parser_module = form.cleaned_data["parser_module"]
#                 account_number = form.cleaned_data["account_number"]
#                 auto_parse = form.cleaned_data["auto_parse"]
#                 files = request.FILES.getlist("files")
#                 uploaded_by = request.user if request.user.is_authenticated else None
#                 results = []
#                 import sys

#                 sys.path.append("/Users/greg/repos/LedgerFlow_AI/PDF-extractor")
#                 from dataextractai.parsers_core.autodiscover import autodiscover_parsers

#                 autodiscover_parsers()
#                 import importlib

#                 registry_mod = importlib.import_module(
#                     "dataextractai.parsers_core.registry"
#                 )
#                 registry = getattr(registry_mod, "ParserRegistry")
#                 for f in files:
#                     result = {"file": f.name}
#                     temp_file_path = None
#                     try:
#                         import tempfile, os

#                         # Save uploaded file to a temp file
#                         with tempfile.NamedTemporaryFile(
#                             delete=False, suffix=os.path.splitext(f.name)[1]
#                         ) as temp_file:
#                             for chunk in f.chunks():
#                                 temp_file.write(chunk)
#                             temp_file_path = temp_file.name
#                         # Always close and flush temp file before using
#                         # Detect parser if needed
#                         used_parser = parser_module
#                         autodetect_debug = ""
#                         if parser_module == "autodetect" or not parser_module:
#                             from dataextractai.parsers.detect import (
#                                 detect_parser_for_file,
#                             )

#                             detected = detect_parser_for_file(temp_file_path)
#                             autodetect_debug = (
#                                 f"detect_parser_for_file({f.name}) => {detected}"
#                             )
#                             if detected:
#                                 used_parser = detected
#                             else:
#                                 result["error"] = "No compatible parser found."
#                                 result["autodetect_debug"] = autodetect_debug
#                                 results.append(result)
#                                 os.unlink(temp_file_path)
#                                 continue
#                         result["parser"] = (
#                             used_parser  # Always show which parser was used
#                         )
#                         result["autodetect_debug"] = autodetect_debug
#                         # Registry mapping debug
#                         registry_mapping = getattr(registry, "_parsers", {})
#                         result["registry_mapping"] = str(
#                             registry_mapping.get(used_parser)
#                         )
#                         # Log temp file info before calling parser
#                         try:
#                             temp_file_size = os.path.getsize(temp_file_path)
#                             with open(temp_file_path, "rb") as tf_dbg:
#                                 temp_file_head = tf_dbg.read(256)
#                             result["temp_file_path"] = temp_file_path
#                             result["temp_file_size"] = temp_file_size
#                             result["temp_file_head"] = temp_file_head.hex()
#                         except Exception as e:
#                             result["temp_file_debug_error"] = (
#                                 f"Failed to read temp file info: {e}"
#                             )
#                         # Import parser module and call main() with positional argument
#                         try:
#                             parser_mod_name = (
#                                 f"dataextractai.parsers.{used_parser}_parser"
#                             )
#                             try:
#                                 parser_mod = importlib.import_module(parser_mod_name)
#                                 parser_main = getattr(parser_mod, "main", None)
#                                 result["parser_module"] = parser_mod_name
#                                 result["main_func"] = str(parser_main)
#                             except ImportError:
#                                 parser_mod_name = f"dataextractai.parsers.{used_parser}"
#                                 parser_mod = importlib.import_module(parser_mod_name)
#                                 parser_main = getattr(parser_mod, "main", None)
#                                 result["parser_module"] = parser_mod_name
#                                 result["main_func"] = str(parser_main)
#                             if not parser_main:
#                                 result["error"] = (
#                                     f"Parser module '{parser_mod_name}' has no main() function."
#                                 )
#                                 results.append(result)
#                                 os.unlink(temp_file_path)
#                                 continue
#                             print(
#                                 f"[DEBUG] Calling {parser_mod_name}.main for file {f.name}"
#                             )
#                             parser_output = parser_main(
#                                 temp_file_path
#                             )  # Positional argument only
#                             # Debug: print parser_output as dict
#                             try:
#                                 from dataextractai.parsers_core.models import (
#                                     ParserOutput,
#                                 )

#                                 if isinstance(parser_output, ParserOutput):
#                                     print(
#                                         f"[DEBUG] parser_output.dict(): {parser_output.dict()}"
#                                     )
#                                 else:
#                                     print(
#                                         f"[DEBUG] parser_output (not ParserOutput): {parser_output}"
#                                     )
#                             except Exception as e:
#                                 print(f"[DEBUG] Exception printing parser_output: {e}")
#                         except Exception as e:
#                             import traceback

#                             tb = traceback.format_exc()
#                             result["error"] = f"Parser error: {e}\n{tb}"
#                             results.append(result)
#                             os.unlink(temp_file_path)
#                             continue
#                         # Validate ParserOutput
#                         try:
#                             from dataextractai.parsers_core.models import ParserOutput

#                             if not isinstance(parser_output, ParserOutput):
#                                 result["error"] = (
#                                     f"Parser did not return ParserOutput. Got: {type(parser_output)}"
#                                 )
#                                 results.append(result)
#                                 os.unlink(temp_file_path)
#                                 continue
#                         except Exception as e:
#                             result["error"] = f"ParserOutput validation error: {e}"
#                             results.append(result)
#                             os.unlink(temp_file_path)
#                             continue
#                         # Extract metadata and transactions
#                         metadata = (
#                             parser_output.metadata.dict()
#                             if parser_output.metadata
#                             else {}
#                         )
#                         transactions = (
#                             [t.dict() for t in parser_output.transactions]
#                             if parser_output.transactions
#                             else []
#                         )
#                         result["normalized"] = True
#                         result["metadata"] = metadata
#                         result["transaction_count"] = len(transactions)
#                         if parser_output.errors:
#                             result["errors"] = parser_output.errors
#                         if parser_output.warnings:
#                             result["warnings"] = parser_output.warnings

#                         # Create StatementFile using the temp file (open in binary mode)
#                         try:
#                             with open(temp_file_path, "rb") as temp_file_for_db:
#                                 django_file = File(temp_file_for_db, name=f.name)
#                                 statement_file = StatementFile.objects.create(
#                                     client=client,
#                                     file=django_file,  # Use Django File wrapper for DB save
#                                     file_type=file_type,
#                                     account_number=metadata.get(
#                                         "account_number", account_number
#                                     ),
#                                     original_filename=f.name,
#                                     uploaded_by=uploaded_by,
#                                     status="uploaded",
#                                     bank=metadata.get("bank_name"),
#                                     year=metadata.get("year"),
#                                     month=metadata.get("month"),
#                                     parser_module=used_parser,
#                                     account_holder_name=metadata.get(
#                                         "account_holder_name"
#                                     ),
#                                     address=metadata.get("address"),
#                                     account_type=metadata.get("account_type"),
#                                     statement_period_start=metadata.get(
#                                         "statement_period_start"
#                                     ),
#                                     statement_period_end=metadata.get(
#                                         "statement_period_end"
#                                     ),
#                                     statement_date=metadata.get("statement_date"),
#                                     parsed_metadata=metadata,
#                                 )
#                                 result["statement_file"] = statement_file.id
#                         except Exception as e:
#                             result["error"] = f"StatementFile creation failed: {e}"
#                             results.append(result)
#                             os.unlink(temp_file_path)
#                             continue
#                         # Restore: Always create transactions for all parsers
#                         transaction_create_results = []
#                         success_count = 0
#                         fail_count = 0
#                         error_list = []
#                         for idx, tx_data in enumerate(transactions):
#                             import logging, traceback

#                             logger = logging.getLogger("batch_upload")
#                             logger.warning(
#                                 f"[DEBUG] Creating transaction idx={idx} raw tx_data={tx_data}"
#                             )
#                             try:
#                                 from profiles.models import Transaction

#                                 tx_fields = {
#                                     "client": client,
#                                     "transaction_date": tx_data.get("transaction_date"),
#                                     "amount": tx_data.get("amount"),
#                                     "description": tx_data.get("description"),
#                                     "category": tx_data.get("category") or "",
#                                     "parsed_data": tx_data,
#                                     "file_path": tx_data.get("file_path")
#                                     or statement_file.file.name,
#                                     "source": tx_data.get("source") or used_parser,
#                                     "transaction_type": tx_data.get("transaction_type")
#                                     or "",
#                                     "normalized_amount": tx_data.get(
#                                         "normalized_amount"
#                                     ),
#                                     "statement_start_date": tx_data.get(
#                                         "statement_start_date"
#                                     )
#                                     or metadata.get("statement_period_start"),
#                                     "statement_end_date": tx_data.get(
#                                         "statement_end_date"
#                                     )
#                                     or metadata.get("statement_period_end"),
#                                     "account_number": tx_data.get("account_number")
#                                     or metadata.get("account_number"),
#                                     "transaction_id": tx_data.get("transaction_id"),
#                                     "normalized_description": tx_data.get(
#                                         "normalized_description"
#                                     ),
#                                     "payee": tx_data.get("payee") or "",
#                                     "confidence": tx_data.get("confidence") or "",
#                                     "reasoning": tx_data.get("reasoning") or "",
#                                     "payee_reasoning": tx_data.get("payee_reasoning")
#                                     or "",
#                                     "business_context": tx_data.get("business_context")
#                                     or "",
#                                     "questions": tx_data.get("questions") or "",
#                                     "classification_type": tx_data.get(
#                                         "classification_type"
#                                     )
#                                     or "None",
#                                     "worksheet": tx_data.get("worksheet") or "",
#                                     "business_percentage": tx_data.get(
#                                         "business_percentage"
#                                     )
#                                     or 100,
#                                     "payee_extraction_method": tx_data.get(
#                                         "payee_extraction_method"
#                                     )
#                                     or "None",
#                                     "classification_method": tx_data.get(
#                                         "classification_method"
#                                     )
#                                     or "None",
#                                     "statement_file": statement_file,
#                                     "parser_name": used_parser,
#                                     "needs_account_number": tx_data.get(
#                                         "needs_account_number", False
#                                     ),
#                                 }
#                                 logger.warning(
#                                     f"[DEBUG] idx={idx} tx_fields before creation: {tx_fields}"
#                                 )
#                                 logger.warning(
#                                     f"[DEBUG] idx={idx} transaction_date type: {type(tx_fields.get('transaction_date'))} value: {tx_fields.get('transaction_date')}"
#                                 )
#                                 tx = Transaction(**tx_fields)
#                                 tx.save()
#                                 logger.warning(
#                                     f"[SUCCESS] idx={idx} Transaction saved with id={tx.id}"
#                                 )
#                                 success_count += 1
#                                 transaction_create_results.append(
#                                     (idx, "success", tx.id)
#                                 )
#                             except Exception as e:
#                                 tb = traceback.format_exc()
#                                 logger.error(
#                                     f"[ERROR] Failed to create transaction idx={idx}: {e}\n{tb}\nData: {tx_data}"
#                                 )
#                                 fail_count += 1
#                                 error_list.append((idx, str(e), tb, tx_data))
#                                 transaction_create_results.append((idx, "fail", str(e)))
#                         logger.warning(
#                             f"[SUMMARY] Transaction creation: attempted={len(transactions)}, succeeded={success_count}, failed={fail_count}"
#                         )
#                         if error_list:
#                             logger.error(f"[SUMMARY] Errors: {error_list}")
#                         result["transactions_created"] = sum(
#                             1 for r in transaction_create_results if r[1] == "success"
#                         )
#                         result["transaction_errors"] = [
#                             r for r in transaction_create_results if r[0] == "fail"
#                         ]
#                         # Only delete temp file after both parsing and DB save are complete
#                         os.unlink(temp_file_path)
#                     except Exception as e:
#                         result["error"] = str(e)
#                         if temp_file_path and os.path.exists(temp_file_path):
#                             os.unlink(temp_file_path)
#                     results.append(result)

#                 from django.contrib import messages

#                 messages.success(
#                     request, f"Processed {len(files)} files. See results below."
#                 )

#                 # Add admin context before rendering results
#                 context = self.admin_site.each_context(request)
#                 context.update(
#                     {
#                         "form": form,
#                         "results": results,
#                         "title": "Batch Upload Statement Files",
#                     }
#                 )
#                 return render(
#                     request, "admin/batch_upload_statement_files.html", context
#                 )
#         else:
#             form = BatchStatementFileUploadForm()

#         context = self.admin_site.each_context(request)
#         context.update(
#             {
#                 "title": "Batch Upload Statement Files",
#                 "form": form,
#             }
#         )
#         return render(request, "admin/batch_upload_statement_files.html", context)

#     def get_urls(self):
#         urls = super().get_urls()
#         custom_urls = [
#             path(
#                 "batch-upload/",
#                 self.admin_site.admin_view(self.batch_upload_view),
#                 name="profiles_statementfile_batch_upload",
#             ),
#         ]
#         return custom_urls + urls  # CUSTOM URLS FIRST


# @admin.register(ParsingRun)
# class ParsingRunAdmin(admin.ModelAdmin):
#     list_display = (
#         "statement_file",
#         "parser_module",
#         "status",
#         "rows_imported",
#         "short_error",
#         "created",
#     )
#     search_fields = (
#         "statement_file__original_filename",
#         "parser_module",
#         "error_message",
#     )
#     list_filter = ("status", "parser_module", "created")

#     def short_error(self, obj):
#         return (
#             (obj.error_message[:60] + "...")
#             if obj.error_message and len(obj.error_message) > 60
#             else obj.error_message
#         )

#     short_error.short_description = "Error Message"
